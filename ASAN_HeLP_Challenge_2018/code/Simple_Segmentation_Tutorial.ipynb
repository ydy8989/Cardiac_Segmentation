{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donghoon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imsave, imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/donghoon/공부자료/Kaggle/Ultrasound Nerve Segmentation/all/'\n",
    "image_rows = 420\n",
    "image_cols = 580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    train_data_path = os.path.join(data_path, 'train')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = int(len(images) / 2)\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_mask = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating training images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        if 'mask' in image_name:\n",
    "            continue\n",
    "        image_mask_name = image_name.split('.')[0] + '_mask.tif'\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "        img_mask = imread(os.path.join(train_data_path, image_mask_name), as_grey=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "        img_mask = np.array([img_mask])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_mask[i] = img_mask\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_train.npy', imgs)\n",
    "    np.save('imgs_mask_train.npy', imgs_mask)\n",
    "    print('Saving to .npy files done.')\n",
    "\n",
    "    \n",
    "def create_test_data():\n",
    "    train_data_path = os.path.join(data_path, 'test')\n",
    "    images = os.listdir(train_data_path)\n",
    "    total = len(images)\n",
    "\n",
    "    imgs = np.ndarray((total, image_rows, image_cols), dtype=np.uint8)\n",
    "    imgs_id = np.ndarray((total, ), dtype=np.int32)\n",
    "\n",
    "    i = 0\n",
    "    print('-'*30)\n",
    "    print('Creating test images...')\n",
    "    print('-'*30)\n",
    "    for image_name in images:\n",
    "        img_id = int(image_name.split('.')[0])\n",
    "        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n",
    "\n",
    "        img = np.array([img])\n",
    "\n",
    "        imgs[i] = img\n",
    "        imgs_id[i] = img_id\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Loading done.')\n",
    "\n",
    "    np.save('imgs_test.npy', imgs)\n",
    "    np.save('imgs_id_test.npy', imgs_id)\n",
    "    print('Saving to .npy files done.')\n",
    "    \n",
    "def load_train_data():\n",
    "    imgs_train = np.load('imgs_train.npy')\n",
    "    imgs_mask_train = np.load('imgs_mask_train.npy')\n",
    "    return imgs_train, imgs_mask_train\n",
    "\n",
    "def load_test_data():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    imgs_id = np.load('imgs_id_test.npy')\n",
    "    return imgs_test, imgs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating training images...\n",
      "------------------------------\n",
      "Done: 0/5635 images\n",
      "Done: 100/5635 images\n",
      "Done: 200/5635 images\n",
      "Done: 300/5635 images\n",
      "Done: 400/5635 images\n",
      "Done: 500/5635 images\n",
      "Done: 600/5635 images\n",
      "Done: 700/5635 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donghoon/anaconda3/lib/python3.6/site-packages/skimage/external/tifffile/tifffile.py:2611: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 800/5635 images\n",
      "Done: 900/5635 images\n",
      "Done: 1000/5635 images\n",
      "Done: 1100/5635 images\n",
      "Done: 1200/5635 images\n",
      "Done: 1300/5635 images\n",
      "Done: 1400/5635 images\n",
      "Done: 1500/5635 images\n",
      "Done: 1600/5635 images\n",
      "Done: 1700/5635 images\n",
      "Done: 1800/5635 images\n",
      "Done: 1900/5635 images\n",
      "Done: 2000/5635 images\n",
      "Done: 2100/5635 images\n",
      "Done: 2200/5635 images\n",
      "Done: 2300/5635 images\n",
      "Done: 2400/5635 images\n",
      "Done: 2500/5635 images\n",
      "Done: 2600/5635 images\n",
      "Done: 2700/5635 images\n",
      "Done: 2800/5635 images\n",
      "Done: 2900/5635 images\n",
      "Done: 3000/5635 images\n",
      "Done: 3100/5635 images\n",
      "Done: 3200/5635 images\n",
      "Done: 3300/5635 images\n",
      "Done: 3400/5635 images\n",
      "Done: 3500/5635 images\n",
      "Done: 3600/5635 images\n",
      "Done: 3700/5635 images\n",
      "Done: 3800/5635 images\n",
      "Done: 3900/5635 images\n",
      "Done: 4000/5635 images\n",
      "Done: 4100/5635 images\n",
      "Done: 4200/5635 images\n",
      "Done: 4300/5635 images\n",
      "Done: 4400/5635 images\n",
      "Done: 4500/5635 images\n",
      "Done: 4600/5635 images\n",
      "Done: 4700/5635 images\n",
      "Done: 4800/5635 images\n",
      "Done: 4900/5635 images\n",
      "Done: 5000/5635 images\n",
      "Done: 5100/5635 images\n",
      "Done: 5200/5635 images\n",
      "Done: 5300/5635 images\n",
      "Done: 5400/5635 images\n",
      "Done: 5500/5635 images\n",
      "Done: 5600/5635 images\n",
      "Loading done.\n",
      "Saving to .npy files done.\n",
      "------------------------------\n",
      "Creating test images...\n",
      "------------------------------\n",
      "Done: 0/5508 images\n",
      "Done: 100/5508 images\n",
      "Done: 200/5508 images\n",
      "Done: 300/5508 images\n",
      "Done: 400/5508 images\n",
      "Done: 500/5508 images\n",
      "Done: 600/5508 images\n",
      "Done: 700/5508 images\n",
      "Done: 800/5508 images\n",
      "Done: 900/5508 images\n",
      "Done: 1000/5508 images\n",
      "Done: 1100/5508 images\n",
      "Done: 1200/5508 images\n",
      "Done: 1300/5508 images\n",
      "Done: 1400/5508 images\n",
      "Done: 1500/5508 images\n",
      "Done: 1600/5508 images\n",
      "Done: 1700/5508 images\n",
      "Done: 1800/5508 images\n",
      "Done: 1900/5508 images\n",
      "Done: 2000/5508 images\n",
      "Done: 2100/5508 images\n",
      "Done: 2200/5508 images\n",
      "Done: 2300/5508 images\n",
      "Done: 2400/5508 images\n",
      "Done: 2500/5508 images\n",
      "Done: 2600/5508 images\n",
      "Done: 2700/5508 images\n",
      "Done: 2800/5508 images\n",
      "Done: 2900/5508 images\n",
      "Done: 3000/5508 images\n",
      "Done: 3100/5508 images\n",
      "Done: 3200/5508 images\n",
      "Done: 3300/5508 images\n",
      "Done: 3400/5508 images\n",
      "Done: 3500/5508 images\n",
      "Done: 3600/5508 images\n",
      "Done: 3700/5508 images\n",
      "Done: 3800/5508 images\n",
      "Done: 3900/5508 images\n",
      "Done: 4000/5508 images\n",
      "Done: 4100/5508 images\n",
      "Done: 4200/5508 images\n",
      "Done: 4300/5508 images\n",
      "Done: 4400/5508 images\n",
      "Done: 4500/5508 images\n",
      "Done: 4600/5508 images\n",
      "Done: 4700/5508 images\n",
      "Done: 4800/5508 images\n",
      "Done: 4900/5508 images\n",
      "Done: 5000/5508 images\n",
      "Done: 5100/5508 images\n",
      "Done: 5200/5508 images\n",
      "Done: 5300/5508 images\n",
      "Done: 5400/5508 images\n",
      "Done: 5500/5508 images\n",
      "Loading done.\n",
      "Saving to .npy files done.\n"
     ]
    }
   ],
   "source": [
    "create_train_data()\n",
    "create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image , train_label =load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5635, 420, 580)\n",
      "(5635, 420, 580)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)\n",
    "print(train_label.shape)\n",
    "# z,y,x 의 numpy array 3차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height ,image_width = 96,96\n",
    "smooth = 1.0 \n",
    "work_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], image_height, image_width), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i],(image_width,image_height),preserve_range=True)\n",
    "        imgs_p = imgs_p[..., np.newaxis]\n",
    "        return imgs_p\n",
    "    \n",
    "def get_unet():\n",
    "    inputs = Input((image_height, image_width, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_and_predict():\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    \n",
    "\n",
    "    train_images = preprocess(train_image)\n",
    "    train_labels = preprocess(train_label)\n",
    "    \n",
    "    train_images = train_images.astype('float32')\n",
    "    mean = np.mean(train_images)  # mean for data centering\n",
    "    std = np.std(train_images)  # std for data normalization\n",
    "\n",
    "    train_images -= mean\n",
    "    train_images /= std\n",
    "\n",
    "    train_labels = train_labels.astype('float32')\n",
    "    train_labels /= 255.  # scale masks to [0, 1]\n",
    "    print(train_images.shape)\n",
    "    print(train_labels.shape)\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    model.fit(train_images, train_labels, batch_size=32, nb_epoch=20, verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "    print(imgs_test.shape)\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'preds'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donghoon/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "train_images = preprocess(train_image)\n",
    "train_labels = preprocess(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5635, 420, 580)\n",
      "(5635, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_image.shape)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(train_label[150,300,25])\n",
    "print(train_labels[50,50,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/donghoon/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "imgs_test, imgs_id_test = load_test_data()\n",
    "imgs_tests = preprocess(imgs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5508, 420, 580)\n",
      "(5508, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "print(imgs_test.shape)\n",
    "print(imgs_tests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
