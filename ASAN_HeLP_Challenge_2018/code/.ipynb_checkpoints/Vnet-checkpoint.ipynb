{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8a3a01e3e73d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls /content/gdrive/My\\\\ Drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!ls /content/gdrive/My\\ Drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Layers\n",
    "def xavier_initializer_convolution(shape, dist='uniform', lambda_initializer=True):\n",
    "    \"\"\"\n",
    "    Xavier initializer for N-D convolution patches. input_activations = patch_volume * in_channels;\n",
    "    output_activations = patch_volume * out_channels; Uniform: lim = sqrt(3/(input_activations + output_activations))\n",
    "    Normal: stddev =  sqrt(6/(input_activations + output_activations))\n",
    "    :param shape: The shape of the convolution patch i.e. spatial_shape + [input_channels, output_channels]. The order of\n",
    "    input_channels and output_channels is irrelevant, hence this can be used to initialize deconvolution parameters.\n",
    "    :param dist: A string either 'uniform' or 'normal' determining the type of distribution\n",
    "    :param lambda_initializer: Whether to return the initial actual values of the parameters (True) or placeholders that\n",
    "    are initialized when the session is initiated\n",
    "    :return: A numpy araray with the initial values for the parameters in the patch\n",
    "    \"\"\"\n",
    "    s = len(shape) - 2\n",
    "    num_activations = np.prod(shape[:s]) * np.sum(shape[s:])  # input_activations + output_activations\n",
    "    if dist == 'uniform':\n",
    "        lim = np.sqrt(6. / num_activations)\n",
    "        if lambda_initializer:\n",
    "            return np.random.uniform(-lim, lim, shape).astype(np.float32)\n",
    "        else:\n",
    "            return tf.random_uniform(shape, minval=-lim, maxval=lim)\n",
    "    if dist == 'normal':\n",
    "        stddev = np.sqrt(3. / num_activations)\n",
    "        if lambda_initializer:\n",
    "            return np.random.normal(0, stddev, shape).astype(np.float32)\n",
    "        else:\n",
    "            tf.truncated_normal(shape, mean=0, stddev=stddev)\n",
    "    raise ValueError('Distribution must be either \"uniform\" or \"normal\".')\n",
    "\n",
    "\n",
    "def constant_initializer(value, shape, lambda_initializer=True):\n",
    "    if lambda_initializer:\n",
    "        return np.full(shape, value).astype(np.float32)\n",
    "    else:\n",
    "        return tf.constant(value, tf.float32, shape)\n",
    "\n",
    "\n",
    "def get_spatial_rank(x):\n",
    "    \"\"\"\n",
    "    :param x: an input tensor with shape [batch_size, ..., num_channels]\n",
    "    :return: the spatial rank of the tensor i.e. the number of spatial dimensions between batch_size and num_channels\n",
    "    \"\"\"\n",
    "    return len(x.get_shape()) - 2\n",
    "\n",
    "\n",
    "def get_num_channels(x):\n",
    "    \"\"\"\n",
    "    :param x: an input tensor with shape [batch_size, ..., num_channels]\n",
    "    :return: the number of channels of x\n",
    "    \"\"\"\n",
    "    return int(x.get_shape()[-1])\n",
    "\n",
    "\n",
    "def get_spatial_size(x):\n",
    "    \"\"\"\n",
    "    :param x: an input tensor with shape [batch_size, ..., num_channels]\n",
    "    :return: The spatial shape of x, excluding batch_size and num_channels.\n",
    "    \"\"\"\n",
    "    return x.get_shape()[1:-1]\n",
    "\n",
    "\n",
    "# parametric leaky relu\n",
    "def prelu(x):\n",
    "    alpha = tf.get_variable('alpha', shape=x.get_shape()[-1], dtype=x.dtype, initializer=tf.constant_initializer(0.1))\n",
    "    return tf.maximum(0.0, x) + alpha * tf.minimum(0.0, x)\n",
    "\n",
    "\n",
    "def convolution(x, filter, padding='SAME', strides=None, dilation_rate=None):\n",
    "    w = tf.get_variable(name='weights', initializer=xavier_initializer_convolution(shape=filter))\n",
    "    b = tf.get_variable(name='biases', initializer=constant_initializer(0, shape=filter[-1]))\n",
    "\n",
    "    return tf.nn.convolution(x, w, padding, strides, dilation_rate) + b\n",
    "\n",
    "\n",
    "def deconvolution(x, filter, output_shape, strides, padding='SAME'):\n",
    "    w = tf.get_variable(name='weights', initializer=xavier_initializer_convolution(shape=filter))\n",
    "    b = tf.get_variable(name='biases', initializer=constant_initializer(0, shape=filter[-2]))\n",
    "\n",
    "    spatial_rank = get_spatial_rank(x)\n",
    "    if spatial_rank == 2:\n",
    "        return tf.nn.conv2d_transpose(x, filter, output_shape, strides, padding) + b\n",
    "    if spatial_rank == 3:\n",
    "        return tf.nn.conv3d_transpose(x, w, output_shape, strides, padding) + b\n",
    "    raise ValueError('Only 2D and 3D images supported.')\n",
    "\n",
    "\n",
    "# More complex blocks\n",
    "\n",
    "# down convolution\n",
    "def down_convolution(x, factor, kernel_size):\n",
    "    num_channels = get_num_channels(x)\n",
    "    spatial_rank = get_spatial_rank(x)\n",
    "    strides = spatial_rank * [factor]\n",
    "    filter = kernel_size + [num_channels, num_channels * factor]\n",
    "    x = convolution(x, filter, strides=strides)\n",
    "    return x\n",
    "\n",
    "\n",
    "# up convolution\n",
    "def up_convolution(x, output_shape, factor, kernel_size):\n",
    "    num_channels = get_num_channels(x)\n",
    "    spatial_rank = get_spatial_rank(x)\n",
    "    strides = [1] + spatial_rank * [factor] + [1]\n",
    "    filter = kernel_size + [num_channels // factor, num_channels]\n",
    "    x = deconvolution(x, filter, output_shape, strides=strides)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c65c67c17e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown_convolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_convolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_num_channels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvolution_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_convolutions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Layers'"
     ]
    }
   ],
   "source": [
    "#Vnet\n",
    "\n",
    "def convolution_block(layer_input, num_convolutions, keep_prob, activation_fn, is_training):\n",
    "    x = layer_input\n",
    "    n_channels = get_num_channels(x)\n",
    "    for i in range(num_convolutions):\n",
    "        with tf.variable_scope('conv_' + str(i+1)):\n",
    "            x = convolution(x, [5, 5, 5, n_channels, n_channels])\n",
    "            if i == num_convolutions - 1:\n",
    "                x = x + layer_input\n",
    "            x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "            x = activation_fn(x)\n",
    "            x = tf.nn.dropout(x, keep_prob)\n",
    "    return x\n",
    "\n",
    "\n",
    "def convolution_block_2(layer_input, fine_grained_features, num_convolutions, keep_prob, activation_fn, is_training):\n",
    "\n",
    "    x = tf.concat((layer_input, fine_grained_features), axis=-1)\n",
    "    n_channels = get_num_channels(layer_input)\n",
    "    if num_convolutions == 1:\n",
    "        with tf.variable_scope('conv_' + str(1)):\n",
    "            x = convolution(x, [5, 5, 5, n_channels * 2, n_channels])\n",
    "            x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "            layer_input = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "            x = x + layer_input\n",
    "            x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "            x = activation_fn(x)\n",
    "            x = tf.nn.dropout(x, keep_prob)\n",
    "        return x\n",
    "\n",
    "    with tf.variable_scope('conv_' + str(1)):\n",
    "        x = convolution(x, [5, 5, 5, n_channels * 2, n_channels])\n",
    "        x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "        x = activation_fn(x)\n",
    "        x = tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "    for i in range(1, num_convolutions):\n",
    "        with tf.variable_scope('conv_' + str(i+1)):\n",
    "            x = convolution(x, [5, 5, 5, n_channels, n_channels])\n",
    "            x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "            layer_input = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "            if i == num_convolutions - 1:\n",
    "                x = x + layer_input\n",
    "            x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "            x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=is_training)\n",
    "            x = activation_fn(x)\n",
    "            x = tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "class VNet(object):\n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 keep_prob=1.0,\n",
    "                 num_channels=16,\n",
    "                 num_levels=4,\n",
    "                 num_convolutions=(1, 2, 3, 3),\n",
    "                 bottom_convolutions=3,\n",
    "                 is_training = True,\n",
    "                 activation_fn=\"relu\"):\n",
    "        \"\"\"\n",
    "        Implements VNet architecture https://arxiv.org/abs/1606.04797\n",
    "        :param num_classes: Number of output classes.\n",
    "        :param keep_prob: Dropout keep probability, set to 1.0 if not training or if no dropout is desired.\n",
    "        :param num_channels: The number of output channels in the first level, this will be doubled every level.\n",
    "        :param num_levels: The number of levels in the network. Default is 4 as in the paper.\n",
    "        :param num_convolutions: An array with the number of convolutions at each level.\n",
    "        :param bottom_convolutions: The number of convolutions at the bottom level of the network.\n",
    "        :param activation_fn: The activation function.\n",
    "        \"\"\"\n",
    "        self.num_classes = num_classes\n",
    "        self.keep_prob = keep_prob\n",
    "        self.num_channels = num_channels\n",
    "        assert num_levels == len(num_convolutions)\n",
    "        self.num_levels = num_levels\n",
    "        self.num_convolutions = num_convolutions\n",
    "        self.bottom_convolutions = bottom_convolutions\n",
    "        self.is_training = is_training\n",
    "\n",
    "        if (activation_fn == \"relu\"):\n",
    "            self.activation_fn = tf.nn.relu\n",
    "        elif(activation_fn == \"prelu\"):\n",
    "            self.activation_fn = prelu\n",
    "\n",
    "    def network_fn(self, x):\n",
    "\n",
    "        keep_prob = self.keep_prob if self.is_training else 1.0\n",
    "        # if the input has more than 1 channel it has to be expanded because broadcasting only works for 1 input\n",
    "        # channel\n",
    "        input_channels = int(x.get_shape()[-1])\n",
    "        with tf.variable_scope('vnet/input_layer'):\n",
    "            if input_channels == 1:\n",
    "                x = tf.tile(x, [1, 1, 1, 1, self.num_channels])\n",
    "                x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=self.is_training)\n",
    "\n",
    "            else:\n",
    "                x = convolution(x, [5, 5, 5, input_channels, self.num_channels])\n",
    "                x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=self.is_training)\n",
    "                x = self.activation_fn(x)\n",
    "\n",
    "        features = list()\n",
    "\n",
    "        for l in range(self.num_levels):\n",
    "            with tf.variable_scope('vnet/encoder/level_' + str(l + 1)):\n",
    "                x = convolution_block(x, self.num_convolutions[l], keep_prob, activation_fn=self.activation_fn, is_training=self.is_training)\n",
    "                features.append(x)\n",
    "                with tf.variable_scope('down_convolution'):\n",
    "                    x = down_convolution(x, factor=2, kernel_size=[2, 2, 2])\n",
    "                    x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=self.is_training)\n",
    "                    x = self.activation_fn(x)\n",
    "\n",
    "        with tf.variable_scope('vnet/bottom_level'):\n",
    "            x = convolution_block(x, self.bottom_convolutions, keep_prob, activation_fn=self.activation_fn, is_training=self.is_training)\n",
    "\n",
    "        for l in reversed(range(self.num_levels)):\n",
    "            with tf.variable_scope('vnet/decoder/level_' + str(l + 1)):\n",
    "                f = features[l]\n",
    "                with tf.variable_scope('up_convolution'):\n",
    "                    x = up_convolution(x, tf.shape(f), factor=2, kernel_size=[2, 2, 2])\n",
    "                    x = tf.layers.batch_normalization(x, momentum=0.99, epsilon=0.001,center=True, scale=True,training=self.is_training)\n",
    "                    x = self.activation_fn(x)\n",
    "\n",
    "                x = convolution_block_2(x, f, self.num_convolutions[l], keep_prob, activation_fn=self.activation_fn, is_training=self.is_training)\n",
    "\n",
    "        with tf.variable_scope('vnet/output_layer'):\n",
    "            logits = convolution(x, [1, 1, 1, self.num_channels, self.num_classes])\n",
    "            logits = tf.layers.batch_normalization(logits, momentum=0.99, epsilon=0.001,center=True, scale=True,training=self.is_training)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "class NiftiDataset(object):\n",
    "  \"\"\"\n",
    "  load image-label pair for training, testing and inference.\n",
    "  Currently only support linear interpolation method\n",
    "  Args:\n",
    "\t\tdata_dir (string): Path to data directory.\n",
    "    image_filename (string): Filename of image data.\n",
    "    label_filename (string): Filename of label data.\n",
    "    transforms (list): List of SimpleITK image transformations.\n",
    "    train (bool): Determine whether the dataset class run in training/inference mode. When set to false, an empty label with same metadata as image is generated.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "    data_dir = '',\n",
    "    image_filename = '',\n",
    "    label_filename = '',\n",
    "    transforms=None,\n",
    "    train=False):\n",
    "\n",
    "    # Init membership variables\n",
    "    self.data_dir = data_dir\n",
    "    self.image_filename = image_filename\n",
    "    self.label_filename = label_filename\n",
    "    self.transforms = transforms\n",
    "    self.train = train\n",
    "\n",
    "  def get_dataset(self):\n",
    "    image_paths = []\n",
    "    label_paths = []\n",
    "    for case in os.listdir(self.data_dir):\n",
    "      image_paths.append(os.path.join(self.data_dir,case,self.image_filename))\n",
    "      label_paths.append(os.path.join(self.data_dir,case,self.label_filename))\n",
    "\n",
    "    dataset = tf.contrib.data.Dataset.from_tensor_slices((image_paths,label_paths))\n",
    "\n",
    "    dataset = dataset.map(lambda image_path, label_path: tuple(tf.py_func(\n",
    "      self.input_parser, [image_path, label_path], [tf.float32,tf.int32])))\n",
    "\n",
    "    self.dataset = dataset\n",
    "    self.data_size = len(image_paths)\n",
    "    return self.dataset\n",
    "\n",
    "  def read_image(self,path):\n",
    "    reader = sitk.ImageFileReader()\n",
    "    reader.SetFileName(path)\n",
    "    return reader.Execute()\n",
    "\n",
    "  def input_parser(self,image_path, label_path):\n",
    "    # read image and label\n",
    "    image = self.read_image(image_path.decode(\"utf-8\"))\n",
    "     # cast image and label\n",
    "    castImageFilter = sitk.CastImageFilter()\n",
    "    castImageFilter.SetOutputPixelType(sitk.sitkInt16)\n",
    "    image = castImageFilter.Execute(image)\n",
    "\n",
    "    if self.train:\n",
    "      label = self.read_image(label_path.decode(\"utf-8\"))\n",
    "      castImageFilter.SetOutputPixelType(sitk.sitkInt8)\n",
    "      label = castImageFilter.Execute(label)\n",
    "    else:\n",
    "      label = sitk.Image(image.GetSize(),sitk.sitkInt8)\n",
    "      label.SetOrigin(image.GetOrigin())\n",
    "      label.SetSpacing(image.GetSpacing())\n",
    "\n",
    "    sample = {'image':image, 'label':label}\n",
    "\n",
    "    if self.transforms:\n",
    "      for transform in self.transforms:\n",
    "        sample = transform(sample)\n",
    "\n",
    "    # convert sample to tf tensors\n",
    "    image_np = sitk.GetArrayFromImage(sample['image'])\n",
    "    label_np = sitk.GetArrayFromImage(sample['label'])\n",
    "\n",
    "    image_np = np.asarray(image_np,np.float32)\n",
    "    label_np = np.asarray(label_np,np.int32)\n",
    "\n",
    "    # to unify matrix dimension order between SimpleITK([x,y,z]) and numpy([z,y,x])\n",
    "    image_np = np.transpose(image_np,(2,1,0))\n",
    "    label_np = np.transpose(label_np,(2,1,0))\n",
    "\n",
    "    return image_np, label_np\n",
    "\n",
    "class Normalization(object):\n",
    "  \"\"\"\n",
    "  Normalize an image to 0 - 255\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    self.name = 'Normalization'\n",
    "\n",
    "  def __call__(self, sample):\n",
    "    # normalizeFilter = sitk.NormalizeImageFilter()\n",
    "    # image, label = sample['image'], sample['label']\n",
    "    # image = normalizeFilter.Execute(image)\n",
    "    resacleFilter = sitk.RescaleIntensityImageFilter()\n",
    "    resacleFilter.SetOutputMaximum(255)\n",
    "    resacleFilter.SetOutputMinimum(0)\n",
    "    image, label = sample['image'], sample['label']\n",
    "    image = resacleFilter.Execute(image)\n",
    "\n",
    "    return {'image': image, 'label': label}\n",
    "\n",
    "class StatisticalNormalization(object):\n",
    "  \"\"\"\n",
    "  Normalize an image by mapping intensity with intensity distribution\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, sigma):\n",
    "    self.name = 'StatisticalNormalization'\n",
    "    assert isinstance(sigma, float)\n",
    "    self.sigma = sigma\n",
    "\n",
    "  def __call__(self, sample):\n",
    "    image, label = sample['image'], sample['label']\n",
    "    statisticsFilter = sitk.StatisticsImageFilter()\n",
    "    statisticsFilter.Execute(image)\n",
    "\n",
    "    intensityWindowingFilter = sitk.IntensityWindowingImageFilter()\n",
    "    intensityWindowingFilter.SetOutputMaximum(255)\n",
    "    intensityWindowingFilter.SetOutputMinimum(0)\n",
    "    intensityWindowingFilter.SetWindowMaximum(statisticsFilter.GetMean()+self.sigma*statisticsFilter.GetSigma());\n",
    "    intensityWindowingFilter.SetWindowMinimum(statisticsFilter.GetMean()-self.sigma*statisticsFilter.GetSigma());\n",
    "\n",
    "    image = intensityWindowingFilter.Execute(image)\n",
    "\n",
    "    return {'image': image, 'label': label}\n",
    "\n",
    "class Resample(object):\n",
    "\n",
    "  def __init__(self, voxel_size):\n",
    "    self.name = 'Resample'\n",
    "\n",
    "    assert isinstance(voxel_size, (float, tuple))\n",
    "    if isinstance(voxel_size, float):\n",
    "      self.voxel_size = (voxel_size, voxel_size, voxel_size)\n",
    "    else:\n",
    "      assert len(voxel_size) == 3\n",
    "      self.voxel_size = voxel_size\n",
    "\n",
    "  def __call__(self, sample):\n",
    "    image, label = sample['image'], sample['label']\n",
    "    \n",
    "    old_spacing = image.GetSpacing()\n",
    "    old_size = image.GetSize()\n",
    "    \n",
    "    new_spacing = self.voxel_size\n",
    "\n",
    "    new_size = []\n",
    "    for i in range(3):\n",
    "      new_size.append(int(math.ceil(old_spacing[i]*old_size[i]/new_spacing[i])))\n",
    "    new_size = tuple(new_size)\n",
    "\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(2)\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetSize(new_size)\n",
    "\n",
    "    # resample on image\n",
    "    resampler.SetOutputOrigin(image.GetOrigin())\n",
    "    resampler.SetOutputDirection(image.GetDirection())\n",
    "    # print(\"Resampling image...\")\n",
    "    image = resampler.Execute(image)\n",
    "\n",
    "    # resample on segmentation\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resampler.SetOutputOrigin(label.GetOrigin())\n",
    "    resampler.SetOutputDirection(label.GetDirection())\n",
    "    # print(\"Resampling segmentation...\")\n",
    "    label = resampler.Execute(label)\n",
    "\n",
    "    return {'image': image, 'label': label}\n",
    "\n",
    "class Padding(object):\n",
    "  \"\"\"\n",
    "  Add padding to the image if size is smaller than patch size\n",
    "\n",
    "\tArgs:\n",
    "\t\toutput_size (tuple or int): Desired output size. If int, a cubic volume is formed\n",
    "\t\"\"\"\n",
    "\n",
    "  def __init__(self, output_size):\n",
    "    self.name = 'Padding'\n",
    "\n",
    "    assert isinstance(output_size, (int, tuple))\n",
    "    if isinstance(output_size, int):\n",
    "      self.output_size = (output_size, output_size, output_size)\n",
    "    else:\n",
    "      assert len(output_size) == 3\n",
    "      self.output_size = output_size\n",
    "\n",
    "    assert all(i > 0 for i in list(self.output_size))\n",
    "\n",
    "  def __call__(self,sample):\n",
    "    image, label = sample['image'], sample['label']\n",
    "    size_old = image.GetSize()\n",
    "\n",
    "    if (size_old[0] >= self.output_size[0]) and (size_old[1] >= self.output_size[1]) and (size_old[2] >= self.output_size[2]):\n",
    "      return sample\n",
    "    else:\n",
    "      self.output_size = list(self.output_size)\n",
    "      if size_old[0] > self.output_size[0]:\n",
    "        self.output_size[0] = size_old[0]\n",
    "      if size_old[1] > self.output_size[1]:\n",
    "        self.output_size[1] = size_old[1]\n",
    "      if size_old[2] > self.output_size[2]:\n",
    "        self.output_size[2] = size_old[2]\n",
    " \n",
    "      self.output_size = tuple(self.output_size)\n",
    "\n",
    "      resampler = sitk.ResampleImageFilter()\n",
    "      resampler.SetOutputSpacing(image.GetSpacing())\n",
    "      resampler.SetSize(self.output_size)\n",
    "\n",
    "      # resample on image\n",
    "      resampler.SetInterpolator(2)\n",
    "      resampler.SetOutputOrigin(image.GetOrigin())\n",
    "      resampler.SetOutputDirection(image.GetDirection())\n",
    "      image = resampler.Execute(image)\n",
    "\n",
    "      # resample on label\n",
    "      resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "      resampler.SetOutputOrigin(label.GetOrigin())\n",
    "      resampler.SetOutputDirection(label.GetDirection())\n",
    "\n",
    "      label = resampler.Execute(label)\n",
    "\n",
    "      return {'image': image, 'label': label}\n",
    "\n",
    "class RandomCrop(object):\n",
    "  \"\"\"\n",
    "  Crop randomly the image in a sample. This is usually used for data augmentation.\n",
    "\tDrop ratio is implemented for randomly dropout crops with empty label. (Default to be 0.2)\n",
    "\tThis transformation only applicable in train mode\n",
    "\n",
    "  Args:\n",
    "    output_size (tuple or int): Desired output size. If int, cubic crop is made.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, output_size, drop_ratio=0.1, min_pixel=1):\n",
    "    self.name = 'Random Crop'\n",
    "\n",
    "    assert isinstance(output_size, (int, tuple))\n",
    "    if isinstance(output_size, int):\n",
    "      self.output_size = (output_size, output_size, output_size)\n",
    "    else:\n",
    "      assert len(output_size) == 3\n",
    "      self.output_size = output_size\n",
    "\n",
    "    assert isinstance(drop_ratio, float)\n",
    "    if drop_ratio >=0 and drop_ratio<=1:\n",
    "      self.drop_ratio = drop_ratio\n",
    "    else:\n",
    "      raise RuntimeError('Drop ratio should be between 0 and 1')\n",
    "\n",
    "    assert isinstance(min_pixel, int)\n",
    "    if min_pixel >=0 :\n",
    "      self.min_pixel = min_pixel\n",
    "    else:\n",
    "      raise RuntimeError('Min label pixel count should be integer larger than 0')\n",
    "\n",
    "  def __call__(self,sample):\n",
    "    image, label = sample['image'], sample['label']\n",
    "    size_old = image.GetSize()\n",
    "    size_new = self.output_size\n",
    "\n",
    "    contain_label = False\n",
    "\n",
    "    roiFilter = sitk.RegionOfInterestImageFilter()\n",
    "    roiFilter.SetSize([size_new[0],size_new[1],size_new[2]])\n",
    "\n",
    "    # statFilter = sitk.StatisticsImageFilter()\n",
    "    # statFilter.Execute(label)\n",
    "    # print(statFilter.GetMaximum(), statFilter.GetSum())\n",
    "\n",
    "    while not contain_label: \n",
    "      # get the start crop coordinate in ijk\n",
    "      if size_old[0] <= size_new[0]:\n",
    "        start_i = 0\n",
    "      else:\n",
    "        start_i = np.random.randint(0, size_old[0]-size_new[0])\n",
    "\n",
    "      if size_old[1] <= size_new[1]:\n",
    "        start_j = 0\n",
    "      else:\n",
    "        start_j = np.random.randint(0, size_old[1]-size_new[1])\n",
    "\n",
    "      if size_old[2] <= size_new[2]:\n",
    "        start_k = 0\n",
    "      else:\n",
    "        start_k = np.random.randint(0, size_old[2]-size_new[2])\n",
    "\n",
    "      roiFilter.SetIndex([start_i,start_j,start_k])\n",
    "\n",
    "      label_crop = roiFilter.Execute(label)\n",
    "      statFilter = sitk.StatisticsImageFilter()\n",
    "      statFilter.Execute(label_crop)\n",
    "\n",
    "      # will iterate until a sub volume containing label is extracted\n",
    "      # pixel_count = seg_crop.GetHeight()*seg_crop.GetWidth()*seg_crop.GetDepth()\n",
    "      # if statFilter.GetSum()/pixel_count<self.min_ratio:\n",
    "      if statFilter.GetSum()<self.min_pixel:\n",
    "        contain_label = self.drop(self.drop_ratio) # has some probabilty to contain patch with empty label\n",
    "      else:\n",
    "        contain_label = True\n",
    "\n",
    "    image_crop = roiFilter.Execute(image)\n",
    "\n",
    "    return {'image': image_crop, 'label': label_crop}\n",
    "\n",
    "  def drop(self,probability):\n",
    "    return random.random() <= probability\n",
    "\n",
    "class RandomNoise(object):\n",
    "  \"\"\"\n",
    "  Randomly noise to the image in a sample. This is usually used for data augmentation.\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    self.name = 'Random Noise'\n",
    "\n",
    "  def __call__(self, sample):\n",
    "    self.noiseFilter = sitk.AdditiveGaussianNoiseImageFilter()\n",
    "    self.noiseFilter.SetMean(0)\n",
    "    self.noiseFilter.SetStandardDeviation(0.1)\n",
    "\n",
    "    # print(\"Normalizing image...\")\n",
    "    image, label = sample['image'], sample['label']\n",
    "    image = self.noiseFilter.Execute(image)\n",
    "\n",
    "    return {'image': image, 'label': label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import NiftiDataset\n",
    "import os\n",
    "import VNet\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# select gpu devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # e.g. \"0,1,2\", \"0,2\" \n",
    "\n",
    "# tensorflow app flags\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('data_dir', '/Users/donghoon/Downloads/vnet-tensorflow/data_sphere/',\n",
    "    \"\"\"Directory of stored data.\"\"\")\n",
    "tf.app.flags.DEFINE_string('image_filename','img.nii',\n",
    "    \"\"\"Image filename\"\"\")\n",
    "tf.app.flags.DEFINE_string('label_filename','label.nii',\n",
    "    \"\"\"Image filename\"\"\")\n",
    "tf.app.flags.DEFINE_integer('batch_size',1,\n",
    "    \"\"\"Size of batch\"\"\")               \n",
    "tf.app.flags.DEFINE_integer('patch_size',128,\n",
    "    \"\"\"Size of a data patch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('patch_layer',128,\n",
    "    \"\"\"Number of layers in data patch\"\"\")\n",
    "tf.app.flags.DEFINE_integer('epochs',10,\n",
    "    \"\"\"Number of epochs for training\"\"\")\n",
    "tf.app.flags.DEFINE_string('log_dir', './tmp/log',\n",
    "    \"\"\"Directory where to write training and testing event logs \"\"\")\n",
    "tf.app.flags.DEFINE_float('init_learning_rate',1e-6,\n",
    "    \"\"\"Initial learning rate\"\"\")\n",
    "tf.app.flags.DEFINE_float('decay_factor',0.01,\n",
    "    \"\"\"Exponential decay learning rate factor\"\"\")\n",
    "tf.app.flags.DEFINE_integer('decay_steps',100,\n",
    "    \"\"\"Number of epoch before applying one learning rate decay\"\"\")\n",
    "tf.app.flags.DEFINE_integer('display_step',10,\n",
    "    \"\"\"Display and logging interval (train steps)\"\"\")\n",
    "tf.app.flags.DEFINE_integer('save_interval',1,\n",
    "    \"\"\"Checkpoint save interval (epochs)\"\"\")\n",
    "tf.app.flags.DEFINE_string('checkpoint_dir', './tmp/ckpt',\n",
    "    \"\"\"Directory where to write checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_string('model_dir','./tmp/model',\n",
    "    \"\"\"Directory to save model\"\"\")\n",
    "tf.app.flags.DEFINE_bool('restore_training',True,\n",
    "    \"\"\"Restore training from last checkpoint\"\"\")\n",
    "tf.app.flags.DEFINE_float('drop_ratio',0,\n",
    "    \"\"\"Probability to drop a cropped area if the label is empty. All empty patches will be dropped for 0 and accept all cropped patches if set to 1\"\"\")\n",
    "tf.app.flags.DEFINE_integer('min_pixel',500,\n",
    "    \"\"\"Minimum non-zero pixels in the cropped label\"\"\")\n",
    "tf.app.flags.DEFINE_integer('shuffle_buffer_size',5,\n",
    "    \"\"\"Number of elements used in shuffle buffer\"\"\")\n",
    "tf.app.flags.DEFINE_string('loss_function','sorensen',\n",
    "    \"\"\"Loss function used in optimization (xent, weight_xent, sorensen, jaccard)\"\"\")\n",
    "tf.app.flags.DEFINE_string('optimizer','sgd',\n",
    "    \"\"\"Optimization method (sgd, adam, momentum, nesterov_momentum)\"\"\")\n",
    "tf.app.flags.DEFINE_float('momentum',0.5,\n",
    "    \"\"\"Momentum used in optimization\"\"\")\n",
    "\n",
    "\n",
    "# tf.app.flags.DEFINE_float('class_weight',0.15,\n",
    "#     \"\"\"The weight used for imbalanced classes data. Currently only apply on binary segmentation class (weight for 0th class, (1-weight) for 1st class)\"\"\")\n",
    "\n",
    "def placeholder_inputs(input_batch_shape, output_batch_shape):\n",
    "    \"\"\"Generate placeholder variables to represent the the input tensors.\n",
    "    These placeholders are used as inputs by the rest of the model building\n",
    "    code and will be fed from the downloaded ckpt in the .run() loop, below.\n",
    "    Args:\n",
    "        patch_shape: The patch_shape will be baked into both placeholders.\n",
    "    Returns:\n",
    "        images_placeholder: Images placeholder.\n",
    "        labels_placeholder: Labels placeholder.\n",
    "    \"\"\"\n",
    "    # Note that the shapes of the placeholders match the shapes of the full\n",
    "    # image and label tensors, except the first dimension is now batch_size\n",
    "    # rather than the full size of the train or test ckpt sets.\n",
    "    # batch_size = -1\n",
    "\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=input_batch_shape, name=\"images_placeholder\")\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=output_batch_shape, name=\"labels_placeholder\")   \n",
    "   \n",
    "    return images_placeholder, labels_placeholder\n",
    "\n",
    "def dice_coe(output, target, loss_type='jaccard', axis=[1, 2, 3], smooth=1e-5):\n",
    "    \"\"\"Soft dice (Sørensen or Jaccard) coefficient for comparing the similarity\n",
    "    of two batch of data, usually be used for binary image segmentation\n",
    "    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    output : Tensor\n",
    "        A distribution with shape: [batch_size, ....], (any dimensions).\n",
    "    target : Tensor\n",
    "        The target distribution, format the same with `output`.\n",
    "    loss_type : str\n",
    "        ``jaccard`` or ``sorensen``, default is ``jaccard``.\n",
    "    axis : tuple of int\n",
    "        All dimensions are reduced, default ``[1,2,3]``.\n",
    "    smooth : float\n",
    "        This small value will be added to the numerator and denominator.\n",
    "            - If both output and target are empty, it makes sure dice is 1.\n",
    "            - If either output or target are empty (all pixels are background), dice = ```smooth/(small_value + smooth)``, then if smooth is very small, dice close to 0 (even the image values lower than the threshold), so in this case, higher smooth can have a higher dice.\n",
    "\n",
    "    Examples\n",
    "    ---------\n",
    "    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\n",
    "    >>> dice_loss = 1 - tl.cost.dice_coe(outputs, y_)\n",
    "\n",
    "    References\n",
    "    -----------\n",
    "    - `Wiki-Dice <https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient>`__\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    inse = tf.reduce_sum(tf.multiply(output,target), axis=axis)\n",
    "\n",
    "    if loss_type == 'jaccard':\n",
    "        l = tf.reduce_sum(tf.multiply(output,output), axis=axis)\n",
    "        r = tf.reduce_sum(tf.multiply(target,target), axis=axis)\n",
    "    elif loss_type == 'sorensen':\n",
    "        l = tf.reduce_sum(output, axis=axis)\n",
    "        r = tf.reduce_sum(target, axis=axis)\n",
    "    else:\n",
    "        raise Exception(\"Unknown loss_type\")\n",
    "    ## old axis=[0,1,2,3]\n",
    "    # dice = 2 * (inse) / (l + r)\n",
    "    # epsilon = 1e-5\n",
    "    # dice = tf.clip_by_value(dice, 0, 1.0-epsilon) # if all empty, dice = 1\n",
    "    ## new haodong\n",
    "    dice = (tf.constant(2.0) * tf.cast(inse,dtype=tf.float32) + tf.constant(smooth)) / (tf.cast(l + r, dtype=tf.float32) + tf.constant(smooth))\n",
    "    ##\n",
    "    dice = tf.reduce_mean(dice)\n",
    "    return dice\n",
    "\n",
    "def train():\n",
    "    \"\"\"Train the Vnet model\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "        # patch_shape(batch_size, height, width, depth, channels)\n",
    "        input_batch_shape = (FLAGS.batch_size, FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer, 1) \n",
    "        output_batch_shape = (FLAGS.batch_size, FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer, 1) \n",
    "        \n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(input_batch_shape,output_batch_shape)\n",
    "\n",
    "        for batch in range(FLAGS.batch_size):\n",
    "            images_log = tf.cast(images_placeholder[batch:batch+1,:,:,:,0], dtype=tf.uint8)\n",
    "            labels_log = tf.cast(tf.scalar_mul(255,labels_placeholder[batch:batch+1,:,:,:,0]), dtype=tf.uint8)\n",
    "\n",
    "            tf.summary.image(\"image\", tf.transpose(images_log,[3,1,2,0]),max_outputs=FLAGS.patch_layer)\n",
    "            tf.summary.image(\"label\", tf.transpose(labels_log,[3,1,2,0]),max_outputs=FLAGS.patch_layer)\n",
    "\n",
    "        # Get images and labels\n",
    "        train_data_dir = os.path.join(FLAGS.data_dir,'training')\n",
    "        test_data_dir = os.path.join(FLAGS.data_dir,'testing')\n",
    "        # support multiple image input, but here only use single channel, label file should be a single file with different classes\n",
    "\n",
    "        # Force input pipepline to CPU:0 to avoid operations sometimes ended up at GPU and resulting a slow down\n",
    "        with tf.device('/cpu:0'):\n",
    "            # create transformations to image and labels\n",
    "            trainTransforms = [\n",
    "                NiftiDataset.StatisticalNormalization(2.5),\n",
    "                # NiftiDataset.Normalization(),\n",
    "                NiftiDataset.Resample((0.45,0.45,0.45)),\n",
    "                NiftiDataset.Padding((FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer)),\n",
    "                NiftiDataset.RandomCrop((FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer),FLAGS.drop_ratio,FLAGS.min_pixel),\n",
    "                NiftiDataset.RandomNoise()\n",
    "                ]\n",
    "\n",
    "            TrainDataset = NiftiDataset.NiftiDataset(\n",
    "                data_dir=train_data_dir,\n",
    "                image_filename=FLAGS.image_filename,\n",
    "                label_filename=FLAGS.label_filename,\n",
    "                transforms=trainTransforms,\n",
    "                train=True\n",
    "                )\n",
    "            \n",
    "            trainDataset = TrainDataset.get_dataset()\n",
    "            trainDataset = trainDataset.shuffle(buffer_size=5)\n",
    "            trainDataset = trainDataset.batch(FLAGS.batch_size)\n",
    "\n",
    "            testTransforms = [\n",
    "                NiftiDataset.StatisticalNormalization(2.5),\n",
    "                # NiftiDataset.Normalization(),\n",
    "                NiftiDataset.Resample((0.45,0.45,0.45)),\n",
    "                NiftiDataset.Padding((FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer)),\n",
    "                NiftiDataset.RandomCrop((FLAGS.patch_size, FLAGS.patch_size, FLAGS.patch_layer),FLAGS.drop_ratio,FLAGS.min_pixel)\n",
    "                ]\n",
    "\n",
    "            TestDataset = NiftiDataset.NiftiDataset(\n",
    "                data_dir=train_data_dir,\n",
    "                image_filename=FLAGS.image_filename,\n",
    "                label_filename=FLAGS.label_filename,\n",
    "                transforms=testTransforms,\n",
    "                train=True\n",
    "            )\n",
    "\n",
    "            testDataset = TestDataset.get_dataset()\n",
    "            testDataset = testDataset.shuffle(buffer_size=5)\n",
    "            testDataset = testDataset.batch(FLAGS.batch_size)\n",
    "            \n",
    "        train_iterator = trainDataset.make_initializable_iterator()\n",
    "        next_element_train = train_iterator.get_next()\n",
    "\n",
    "        test_iterator = testDataset.make_initializable_iterator()\n",
    "        next_element_test = test_iterator.get_next()\n",
    "\n",
    "        # Initialize the model\n",
    "        with tf.name_scope(\"vnet\"):\n",
    "            model = VNet.VNet(\n",
    "                num_classes=2, # binary for 2\n",
    "                keep_prob=1.0, # default 1\n",
    "                num_channels=16, # default 16 \n",
    "                num_levels=4,  # default 4\n",
    "                num_convolutions=(1,2,3,3), # default (1,2,3,3), size should equal to num_levels\n",
    "                bottom_convolutions=3, # default 3\n",
    "                activation_fn=\"prelu\") # default relu\n",
    "\n",
    "            logits = model.network_fn(images_placeholder)\n",
    "\n",
    "        for batch in range(FLAGS.batch_size):\n",
    "            logits_max = tf.reduce_max(logits[batch:batch+1,:,:,:,:])\n",
    "            logits_min = tf.reduce_min(logits[batch:batch+1,:,:,:,:])\n",
    "\n",
    "            logits_log_0 = logits[batch:batch+1,:,:,:,0]\n",
    "            logits_log_1 = logits[batch:batch+1,:,:,:,1]\n",
    "\n",
    "            # normalize to 0-255 range\n",
    "            logits_log_0 = tf.cast((logits_log_0-logits_min)*255./(logits_max-logits_min), dtype=tf.uint8)\n",
    "            logits_log_1 = tf.cast((logits_log_1-logits_min)*255./(logits_max-logits_min), dtype=tf.uint8)\n",
    "\n",
    "            tf.summary.image(\"logits_0\", tf.transpose(logits_log_0,[3,1,2,0]),max_outputs=FLAGS.patch_layer)\n",
    "            tf.summary.image(\"logits_1\", tf.transpose(logits_log_1,[3,1,2,0]),max_outputs=FLAGS.patch_layer)\n",
    "\n",
    "        # # Exponential decay learning rate\n",
    "        # train_batches_per_epoch = math.ceil(TrainDataset.data_size/FLAGS.batch_size)\n",
    "        # decay_steps = train_batches_per_epoch*FLAGS.decay_steps\n",
    "\n",
    "        with tf.name_scope(\"learning_rate\"):\n",
    "            learning_rate = FLAGS.init_learning_rate\n",
    "        #     learning_rate = tf.train.exponential_decay(FLAGS.init_learning_rate,\n",
    "        #         global_step,\n",
    "        #         decay_steps,\n",
    "        #         FLAGS.decay_factor,\n",
    "        #         staircase=True)\n",
    "        tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "        # softmax op for probability layer\n",
    "        with tf.name_scope(\"softmax\"):\n",
    "            softmax_op = tf.nn.softmax(logits,name=\"softmax\")\n",
    "\n",
    "        for batch in range(FLAGS.batch_size):\n",
    "            # grayscale to rainbow colormap, convert to HSV (H = reversed grayscale from 0:2/3, S and V are all 1)\n",
    "            # then convert to RGB\n",
    "            softmax_log_0H = (1. - tf.transpose(softmax_op[batch:batch+1,:,:,:,0],[3,1,2,0]))*2./3.\n",
    "            softmax_log_1H = (1. - tf.transpose(softmax_op[batch:batch+1,:,:,:,1],[3,1,2,0]))*2./3.\n",
    "\n",
    "            softmax_log_0H = tf.squeeze(softmax_log_0H,axis=-1)\n",
    "            softmax_log_1H = tf.squeeze(softmax_log_1H,axis=-1)\n",
    "            softmax_log_SV = tf.ones(softmax_log_0H.get_shape())\n",
    "\n",
    "            softmax_log_0 = tf.stack([softmax_log_0H,softmax_log_SV,softmax_log_SV], axis=3)\n",
    "            softmax_log_1 = tf.stack([softmax_log_1H,softmax_log_SV,softmax_log_SV], axis=3)\n",
    "\n",
    "            softmax_log_0 = tf.image.hsv_to_rgb(softmax_log_0)\n",
    "            softmax_log_1 = tf.image.hsv_to_rgb(softmax_log_1)\n",
    "\n",
    "            softmax_log_0 = tf.cast(tf.scalar_mul(255,softmax_log_0), dtype=tf.uint8)\n",
    "            softmax_log_1 = tf.cast(tf.scalar_mul(255,softmax_log_1), dtype=tf.uint8)\n",
    "           \n",
    "            tf.summary.image(\"softmax_0\", softmax_log_0,max_outputs=FLAGS.patch_layer)\n",
    "            tf.summary.image(\"softmax_1\", softmax_log_1,max_outputs=FLAGS.patch_layer)\n",
    "\n",
    "            # # this is grayscale one\n",
    "            # softmax_log_0 = tf.cast(tf.scalar_mul(255,softmax_op[batch:batch+1,:,:,:,0]), dtype=tf.uint8)\n",
    "            # softmax_log_1 = tf.cast(tf.scalar_mul(255,softmax_op[batch:batch+1,:,:,:,1]), dtype=tf.uint8)\n",
    "            # tf.summary.image(\"softmax_0\", tf.transpose(softmax_log_0,[3,1,2,0]),max_outputs=FLAGS.patch_layer)\n",
    "            # tf.summary.image(\"softmax_1\", tf.transpose(softmax_log_1,[3,1,2,0]),max_outputs=FLAGS.patch_layer)\n",
    "\n",
    "        # Op for calculating loss\n",
    "        with tf.name_scope(\"cross_entropy\"):\n",
    "            loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=logits,\n",
    "                labels=tf.squeeze(labels_placeholder, \n",
    "                squeeze_dims=[4])))\n",
    "        tf.summary.scalar('loss',loss_op)\n",
    "\n",
    "        with tf.name_scope(\"weighted_cross_entropy\"):\n",
    "            class_weights = tf.constant([1.0, 1.0])\n",
    "\n",
    "            # deduce weights for batch samples based on their true label\n",
    "            onehot_labels = tf.one_hot(tf.squeeze(labels_placeholder,squeeze_dims=[4]),depth = 2)\n",
    "\n",
    "            weights = tf.reduce_sum(class_weights * onehot_labels, axis=-1)\n",
    "            # compute your (unweighted) softmax cross entropy loss\n",
    "            unweighted_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=logits,\n",
    "                labels=tf.squeeze(labels_placeholder, \n",
    "                squeeze_dims=[4]))\n",
    "            # apply the weights, relying on broadcasting of the multiplication\n",
    "            weighted_loss = unweighted_loss * weights\n",
    "            # reduce the result to get your final loss\n",
    "            weighted_loss_op = tf.reduce_mean(weighted_loss)\n",
    "                \n",
    "        tf.summary.scalar('weighted_loss',weighted_loss_op)\n",
    "\n",
    "        # Argmax Op to generate label from logits\n",
    "        with tf.name_scope(\"predicted_label\"):\n",
    "            pred = tf.argmax(logits, axis=4 , name=\"prediction\")\n",
    "\n",
    "        for batch in range(FLAGS.batch_size):\n",
    "            pred_log = tf.cast(tf.scalar_mul(255,pred[batch:batch+1,:,:,:]), dtype=tf.uint8)\n",
    "            tf.summary.image(\"pred\", tf.transpose(pred_log,[3,1,2,0]),max_outputs=FLAGS.patch_layer)\n",
    "\n",
    "        # Accuracy of model\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_pred = tf.equal(tf.expand_dims(pred,-1), tf.cast(labels_placeholder,dtype=tf.int64))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "        # Dice Similarity, currently only for binary segmentation\n",
    "        with tf.name_scope(\"dice\"):\n",
    "            # sorensen = dice_coe(tf.expand_dims(softmax_op[:,:,:,:,1],-1),tf.cast(labels_placeholder,dtype=tf.float32), loss_type='sorensen')\n",
    "            # jaccard = dice_coe(tf.expand_dims(softmax_op[:,:,:,:,1],-1),tf.cast(labels_placeholder,dtype=tf.float32), loss_type='jaccard')\n",
    "            sorensen = dice_coe(softmax_op,tf.cast(tf.one_hot(labels_placeholder[:,:,:,:,0],depth=2),dtype=tf.float32), loss_type='sorensen', axis=[1,2,3,4])\n",
    "            jaccard = dice_coe(softmax_op,tf.cast(tf.one_hot(labels_placeholder[:,:,:,:,0],depth=2),dtype=tf.float32), loss_type='jaccard', axis=[1,2,3,4])\n",
    "            sorensen_loss = 1. - sorensen\n",
    "            jaccard_loss = 1. - jaccard\n",
    "        tf.summary.scalar('sorensen', sorensen)\n",
    "        tf.summary.scalar('jaccard', jaccard)\n",
    "        tf.summary.scalar('sorensen_loss', sorensen_loss)\n",
    "        tf.summary.scalar('jaccard_loss',jaccard_loss)\n",
    "\n",
    "        # Training Op\n",
    "        with tf.name_scope(\"training\"):\n",
    "            # optimizer\n",
    "            if FLAGS.optimizer == \"sgd\":\n",
    "                optimizer = tf.train.GradientDescentOptimizer(learning_rate=FLAGS.init_learning_rate)\n",
    "            elif FLAGS.optimizer == \"adam\":\n",
    "                optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.init_learning_rate)\n",
    "            elif FLAGS.optimizer == \"momentum\":\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate=FLAGS.init_learning_rate, momentum=FLAGS.momentum)\n",
    "            elif FLAGS.optimizer == \"nesterov_momentum\":\n",
    "                optimizer = tf.train.MomentumOptimizer(learning_rate=FLAGS.init_learning_rate, momentum=FLAGS.momentum, use_nesterov=True)\n",
    "            else:\n",
    "                sys.exit(\"Invalid optimizer\");\n",
    "\n",
    "            # loss function\n",
    "            if (FLAGS.loss_function == \"xent\"):\n",
    "                loss_fn = loss_op\n",
    "            elif(FLAGS.loss_function == \"weight_xent\"):\n",
    "                loss_fn = weighted_loss_op\n",
    "            elif(FLAGS.loss_function == \"sorensen\"):\n",
    "                loss_fn = sorensen_loss\n",
    "            elif(FLAGS.loss_function == \"jaccard\"):\n",
    "                loss_fn = jaccard_loss\n",
    "            else:\n",
    "                sys.exit(\"Invalid loss function\");\n",
    "\n",
    "            train_op = optimizer.minimize(\n",
    "                loss = loss_fn,\n",
    "                global_step=global_step)\n",
    "\n",
    "        # # epoch checkpoint manipulation\n",
    "        start_epoch = tf.get_variable(\"start_epoch\", shape=[1], initializer= tf.zeros_initializer,dtype=tf.int32)\n",
    "        start_epoch_inc = start_epoch.assign(start_epoch+1)\n",
    "\n",
    "        # saver\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        checkpoint_prefix = os.path.join(FLAGS.checkpoint_dir ,\"checkpoint\")\n",
    "        print(\"Setting up Saver...\")\n",
    "        saver = tf.train.Saver(keep_checkpoint_every_n_hours=5)\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "        # config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "        # training cycle\n",
    "        with tf.Session(config=config) as sess:\n",
    "            # Initialize all variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"{}: Start training...\".format(datetime.datetime.now()))\n",
    "\n",
    "            # summary writer for tensorboard\n",
    "            train_summary_writer = tf.summary.FileWriter(FLAGS.log_dir + '/train', sess.graph)\n",
    "            test_summary_writer = tf.summary.FileWriter(FLAGS.log_dir + '/test', sess.graph)\n",
    "\n",
    "            # restore from checkpoint\n",
    "            if FLAGS.restore_training:\n",
    "                # check if checkpoint exists\n",
    "                if os.path.exists(checkpoint_prefix+\"-latest\"):\n",
    "                    print(\"{}: Last checkpoint found at {}, loading...\".format(datetime.datetime.now(),FLAGS.checkpoint_dir))\n",
    "                    latest_checkpoint_path = tf.train.latest_checkpoint(FLAGS.checkpoint_dir,latest_filename=\"checkpoint-latest\")\n",
    "                    saver.restore(sess, latest_checkpoint_path)\n",
    "            \n",
    "            print(\"{}: Last checkpoint epoch: {}\".format(datetime.datetime.now(),start_epoch.eval()[0]))\n",
    "            print(\"{}: Last checkpoint global step: {}\".format(datetime.datetime.now(),tf.train.global_step(sess, global_step)))\n",
    "\n",
    "            # loop over epochs\n",
    "            for epoch in np.arange(start_epoch.eval(), FLAGS.epochs):\n",
    "                # initialize iterator in each new epoch\n",
    "                sess.run(train_iterator.initializer)\n",
    "                sess.run(test_iterator.initializer)\n",
    "                print(\"{}: Epoch {} starts\".format(datetime.datetime.now(),epoch+1))\n",
    "\n",
    "                # training phase\n",
    "                while True:\n",
    "                    try:\n",
    "                        [image, label] = sess.run(next_element_train)\n",
    "\n",
    "                        image = image[:,:,:,:,np.newaxis]\n",
    "                        label = label[:,:,:,:,np.newaxis]\n",
    "                        \n",
    "                        model.is_training = True;\n",
    "                        train, summary = sess.run([train_op, summary_op], feed_dict={images_placeholder: image, labels_placeholder: label})\n",
    "                        train_summary_writer.add_summary(summary, global_step=tf.train.global_step(sess, global_step))\n",
    "\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        start_epoch_inc.op.run()\n",
    "                        # print(start_epoch.eval())\n",
    "                        # save the model at end of each epoch training\n",
    "                        print(\"{}: Saving checkpoint of epoch {} at {}...\".format(datetime.datetime.now(),epoch+1,FLAGS.checkpoint_dir))\n",
    "                        if not (os.path.exists(FLAGS.checkpoint_dir)):\n",
    "                            os.makedirs(FLAGS.checkpoint_dir,exist_ok=True)\n",
    "                        saver.save(sess, checkpoint_prefix, \n",
    "                            global_step=tf.train.global_step(sess, global_step),\n",
    "                            latest_filename=\"checkpoint-latest\")\n",
    "                        print(\"{}: Saving checkpoint succeed\".format(datetime.datetime.now()))\n",
    "                        break\n",
    "                \n",
    "                # testing phase\n",
    "                print(\"{}: Training of epoch {} finishes, testing start\".format(datetime.datetime.now(),epoch+1))\n",
    "                while True:\n",
    "                    try:\n",
    "                        [image, label] = sess.run(next_element_test)\n",
    "\n",
    "                        image = image[:,:,:,:,np.newaxis]\n",
    "                        label = label[:,:,:,:,np.newaxis]\n",
    "                        \n",
    "                        model.is_training = False;\n",
    "                        loss, summary = sess.run([loss_op, summary_op], feed_dict={images_placeholder: image, labels_placeholder: label})\n",
    "                        test_summary_writer.add_summary(summary, global_step=tf.train.global_step(sess, global_step))\n",
    "\n",
    "                    except tf.errors.OutOfRangeError:\n",
    "                        break\n",
    "\n",
    "        # close tensorboard summary writer\n",
    "        train_summary_writer.close()\n",
    "        test_summary_writer.close()\n",
    "\n",
    "def main(argv=None):\n",
    "    if not FLAGS.restore_training:\n",
    "        # clear log directory\n",
    "        if tf.gfile.Exists(FLAGS.log_dir):\n",
    "            tf.gfile.DeleteRecursively(FLAGS.log_dir)\n",
    "        tf.gfile.MakeDirs(FLAGS.log_dir)\n",
    "\n",
    "        # clear checkpoint directory\n",
    "        if tf.gfile.Exists(FLAGS.checkpoint_dir):\n",
    "            tf.gfile.DeleteRecursively(FLAGS.checkpoint_dir)\n",
    "        tf.gfile.MakeDirs(FLAGS.checkpoint_dir)\n",
    "\n",
    "        # # clear model directory\n",
    "        # if tf.gfile.Exists(FLAGS.model_dir):\n",
    "        #     tf.gfile.DeleteRecursively(FLGAS.model_dir)\n",
    "        # tf.gfile.MakeDirs(FLAGS.model_dir)\n",
    "\n",
    "    train()\n",
    "\n",
    "if __name__=='__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
